{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import preprocessing \n",
    "from xgboost import XGBRegressor\n",
    "from datetime import datetime\n",
    "from bayes_opt import BayesianOptimization\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performce cross validation using xgboost\n",
    "def xgboostcv(X, y, fold, n_estimators, lr, depth, n_jobs, gamma, min_cw, subsample, colsample):\n",
    "    uid = np.unique(fold)\n",
    "    model_pred = np.zeros(X.shape[0])\n",
    "    model_valid_loss = np.zeros(len(uid))\n",
    "    model_train_loss = np.zeros(len(uid))\n",
    "    for i in uid:\n",
    "        x_valid = X[fold==i]\n",
    "        x_train = X[fold!=i]\n",
    "        y_valid = y[fold==i]\n",
    "        y_train = y[fold!=i]\n",
    "        model = XGBRegressor(n_estimators=n_estimators, learning_rate=lr, \n",
    "                           max_depth = depth, n_jobs = n_jobs, \n",
    "                           gamma = gamma, min_child_weight = min_cw,\n",
    "                           subsample = subsample, colsample_bytree = colsample, random_state=1234)\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        pred = model.predict(x_valid)\n",
    "        model_pred[fold==i] = pred\n",
    "        model_valid_loss[uid==i] = mean_squared_error(y_valid, pred)\n",
    "        model_train_loss[uid==i] = mean_squared_error(y_train, model.predict(x_train))\n",
    "    return {'pred':model_pred, 'valid_loss':model_valid_loss, 'train_loss':model_train_loss}\n",
    "\n",
    "# Compute MSE for xgboost cross validation\n",
    "def xgboostcv_mse(n, p, depth, g, min_cw, subsample, colsample):\n",
    "    model_cv = xgboostcv(X_train, y_train, fold_train, \n",
    "                         int(n)*100, 10**p, int(depth), n_nodes, \n",
    "                         10**g, min_cw, subsample, colsample)\n",
    "    MSE = mean_squared_error(y_train, model_cv['pred'])\n",
    "    return -MSE\n",
    "\n",
    "# Display model performance metrics for each cv iteration\n",
    "def cv_performance(model, y, fold):\n",
    "    uid = np.unique(fold)\n",
    "    pred = np.round(model['pred'])\n",
    "    y = y.reshape(-1)\n",
    "    model_valid_mse = np.zeros(len(uid))\n",
    "    model_valid_mae = np.zeros(len(uid))\n",
    "    model_valid_r2 = np.zeros(len(uid))\n",
    "    for i in uid:\n",
    "        pred_i = pred[fold==i]\n",
    "        y_i = y[fold==i]\n",
    "        model_valid_mse[uid==i] = mean_squared_error(y_i, pred_i)\n",
    "        model_valid_mae[uid==i] = np.abs(pred_i-y_i).mean()\n",
    "        model_valid_r2[uid==i] = r2_score(y_i, pred_i)\n",
    "    \n",
    "    results = pd.DataFrame(0, index=uid, \n",
    "                           columns=['valid_mse', 'valid_mae', 'valid_r2', \n",
    "                                    'valid_loss', 'train_loss'])\n",
    "    results['valid_mse'] = model_valid_mse\n",
    "    results['valid_mae'] = model_valid_mae\n",
    "    results['valid_r2'] = model_valid_r2\n",
    "    results['valid_loss'] = model['valid_loss']\n",
    "    results['train_loss'] = model['train_loss']\n",
    "    print(results)\n",
    "\n",
    "# Display overall model performance metrics\n",
    "def cv_overall_performance(y, y_pred):\n",
    "    overall_MSE = mean_squared_error(y, y_pred)\n",
    "    overall_MAE = (np.abs(y_pred-y)).mean()\n",
    "    overall_RMSE = np.sqrt(np.square(y_pred-y).mean())\n",
    "    overall_R2 = r2_score(y, y_pred)\n",
    "    print(\"XGB overall MSE: %0.4f\" %overall_MSE)\n",
    "    print(\"XGB overall MAE: %0.4f\" %overall_MAE)\n",
    "    print(\"XGB overall RMSE: %0.4f\" %overall_RMSE)\n",
    "    print(\"XGB overall R^2: %0.4f\" %overall_R2)    \n",
    "\n",
    "# Plot variable importance\n",
    "def plot_importance(model, columns):\n",
    "    importances = pd.Series(model.feature_importances_, index = columns).sort_values(ascending=False)\n",
    "    n = len(columns)\n",
    "    plt.figure(figsize=(10,15))\n",
    "    plt.barh(np.arange(n)+0.5, importances)\n",
    "    plt.yticks(np.arange(0.5,n+0.5), importances.index)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=22)\n",
    "    plt.ylim([0,n])\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.savefig('variable_importance.png', dpi = 150)\n",
    "\n",
    "# Save xgboost model\n",
    "def save(obj, path):\n",
    "    pkl_fl = open(path, 'wb')\n",
    "    pickle.dump(obj, pkl_fl)\n",
    "    pkl_fl.close()\n",
    "\n",
    "# Load xgboost model\n",
    "def load(path):\n",
    "    f = open(path, 'rb')\n",
    "    obj = pickle.load(f)\n",
    "    f.close()\n",
    "    return(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a few values\n",
    "validation_only = False # Whether test model with test data\n",
    "n_nodes = 96 # Number of computing nodes used for hyperparamter tunning\n",
    "trained = False # If a trained model exits\n",
    "cols_drop = ['Temp', 'WindSp', 'Precip', 'Snow', 'StationId', 'NumberOfLanes', 'Dir', 'FC'] # Columns to be dropped\n",
    "if trained:\n",
    "    params = load('params.dat')\n",
    "    xgb_cv = load('xgb_cv.dat')\n",
    "    xgb = load('xgb.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validation_only:\n",
    "    raw_data_train = pd.read_csv(\"final_train_data_adt.csv\")\n",
    "    data = raw_data_train.drop(cols_drop, axis=1)\n",
    "    if 'Dir' in data.columns:\n",
    "        data[['Dir']] = data[['Dir']].astype('category')\n",
    "        one_hot = pd.get_dummies(data[['Dir']])\n",
    "        data = data.drop(['Dir'], axis = 1)\n",
    "        data = data.join(one_hot)\n",
    "    if 'FC' in data.columns:\n",
    "        data[['FC']] = data[['FC']].astype('category')\n",
    "        one_hot = pd.get_dummies(data[['FC']])\n",
    "        data = data.drop(['FC'], axis = 1)\n",
    "        data = data.join(one_hot)\n",
    "    week_dict = {\"DayOfWeek\": {'Monday': 1, 'Tuesday': 2, 'Wednesday': 3, 'Thursday': 4, \n",
    "                               'Friday': 5, 'Saturday': 6, 'Sunday': 7}}\n",
    "    data = data.replace(week_dict)\n",
    "\n",
    "    X = data.drop(['Volume', 'fold'], axis=1)\n",
    "    X_col = X.columns\n",
    "    y = data[['Volume']]\n",
    "\n",
    "    fold_train = data[['fold']].values.reshape(-1)\n",
    "    X_train = X.values\n",
    "    y_train = y.values\n",
    "    \n",
    "else:\n",
    "    raw_data_train = pd.read_csv(\"final_train_data_adt.csv\")\n",
    "    raw_data_test = pd.read_csv(\"final_test_data_adt.csv\")\n",
    "    raw_data_test1 = pd.DataFrame(np.concatenate((raw_data_test.values, np.zeros(raw_data_test.shape[0]).reshape(-1, 1)), axis=1),\n",
    "                                 columns = raw_data_test.columns.append(pd.Index(['fold'])))\n",
    "    raw_data = pd.DataFrame(np.concatenate((raw_data_train.values, raw_data_test1.values), axis=0), \n",
    "                            columns = raw_data_train.columns)\n",
    "\n",
    "    data = raw_data.drop(cols_drop, axis=1)\n",
    "    if 'Dir' in data.columns:\n",
    "        data[['Dir']] = data[['Dir']].astype('category')\n",
    "        one_hot = pd.get_dummies(data[['Dir']])\n",
    "        data = data.drop(['Dir'], axis = 1)\n",
    "        data = data.join(one_hot)\n",
    "    if 'FC' in data.columns:\n",
    "        data[['FC']] = data[['FC']].astype('category')\n",
    "        one_hot = pd.get_dummies(data[['FC']])\n",
    "        data = data.drop(['FC'], axis = 1)\n",
    "        data = data.join(one_hot)\n",
    "    week_dict = {\"DayOfWeek\": {'Monday': 1, 'Tuesday': 2, 'Wednesday': 3, 'Thursday': 4, \n",
    "                               'Friday': 5, 'Saturday': 6, 'Sunday': 7}}\n",
    "    data = data.replace(week_dict)\n",
    "\n",
    "    X = data.drop(['Volume'], axis=1)\n",
    "    y = data[['Volume']]\n",
    "\n",
    "    X_train = X.loc[X.fold!=0, :]\n",
    "    fold_train = X_train[['fold']].values.reshape(-1)\n",
    "    X_col = X_train.drop(['fold'], axis = 1).columns\n",
    "    X_train = X_train.drop(['fold'], axis = 1).values\n",
    "    y_train = y.loc[X.fold!=0, :].values\n",
    "\n",
    "    X_test = X.loc[X.fold==0, :]\n",
    "    X_test = X_test.drop(['fold'], axis = 1).values\n",
    "    y_test = y.loc[X.fold==0, :].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain variable names\n",
    "X_name_dict = {'Temp': 'Temperature', 'WindSp': 'Wind Speed', 'Precip': 'Precipitation', 'Snow': 'Snow', \n",
    "               'Long': 'Longitude', 'Lat': 'Latitude', 'NumberOfLanes': 'Number of Lanes', 'SpeedLimit': 'Speed Limit', \n",
    "               'FRC': 'TomTom FRC', 'DayOfWeek': 'Day of Week', 'Month': 'Month', 'Hour': 'Hour', \n",
    "               'AvgSp': 'Average Speed', 'ProbeCount': 'Probe Count', 'Dir_E': 'Direction(East)', \n",
    "               'Dir_N': 'Direction(North)', 'Dir_S': 'Direction(South)', 'Dir_W': 'Direction(West)', \n",
    "               'FC_3R': 'FHWA FC(3R)', 'FC_3U': 'FHWA FC(3U)', 'FC_4R': 'FHWA FC(4R)', 'FC_4U': 'FHWA FC(4U)', \n",
    "               'FC_5R': 'FHWA FC(5R)', 'FC_5U': 'FHWA FC(5U)', 'FC_7R': 'FHWA FC(7R)', 'FC_7U': 'FHWA FC(7U)'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validation_only == False:\n",
    "    print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation & Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameter ranges for Bayesian optimization \n",
    "xgboostBO = BayesianOptimization(xgboostcv_mse,\n",
    "                                 {'n': (1, 10),\n",
    "                                  'p': (-4, 0),\n",
    "                                  'depth': (2, 10),\n",
    "                                  'g': (-3, 0),\n",
    "                                  'min_cw': (1, 10), \n",
    "                                  'subsample': (0.5, 1), \n",
    "                                  'colsample': (0.5, 1)\n",
    "                                 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Bayesian optimization to tune hyperparameters\n",
    "import time\n",
    "start_time = time.time()\n",
    "xgboostBO.maximize(init_points=10, n_iter = 50)\n",
    "print('-'*53)\n",
    "print('Final Results')\n",
    "print('XGBOOST: %f' % xgboostBO.max['target'])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the hyperparameters the yield the highest model performance\n",
    "params = xgboostBO.max['params']\n",
    "save(params, 'params.dat')\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross validation using the optimal hyperparameters\n",
    "xgb_cv = xgboostcv(X_train, y_train, fold_train, int(params['n'])*100, \n",
    "                   10**params['p'], int(params['depth']), n_nodes, \n",
    "                   10**params['g'], params['min_cw'], params['subsample'], params['colsample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display cv results for each iteration\n",
    "cv_performance(xgb_cv, y_train, fold_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display overall cv results\n",
    "cv_pred = xgb_cv['pred']\n",
    "cv_pred[cv_pred<0] = 0\n",
    "cv_overall_performance(y_train.reshape(-1), cv_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cv results\n",
    "save(xgb_cv, 'xgb_cv.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a xgboost using all the training data with the optimal hyperparameter\n",
    "xgb = XGBRegressor(n_estimators=int(params['n'])*100, learning_rate=10**params['p'], max_depth = int(params['depth']), \n",
    "                   n_jobs = n_nodes, gamma = 10**params['g'], min_child_weight = params['min_cw'], \n",
    "                   subsample = params['subsample'], colsample_bytree = params['colsample'], random_state=1234)\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained model with test data\n",
    "if validation_only == False:\n",
    "    y_pred = xgb.predict(X_test)\n",
    "    y_pred[y_pred<0] = 0\n",
    "    cv_overall_performance(y_test.reshape(-1), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot variable importance\n",
    "col_names = [X_name_dict[i] for i in X_col]\n",
    "plot_importance(xgb, col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the trained xgboost model\n",
    "save(xgb, 'xgb.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce cross validation estimates or estimates for test data\n",
    "train_data_pred = pd.DataFrame(np.concatenate((raw_data_train.values, cv_pred.reshape(-1, 1)), axis=1),\n",
    "                              columns = raw_data_train.columns.append(pd.Index(['PredVolume'])))\n",
    "train_data_pred.to_csv('train_data_adt_pred.csv', index = False)\n",
    "\n",
    "if validation_only == False:\n",
    "    test_data_pred = pd.DataFrame(np.concatenate((raw_data_test.values, y_pred.reshape(-1, 1)), axis=1),\n",
    "                              columns = raw_data_test.columns.append(pd.Index(['PredVolume'])))\n",
    "    test_data_pred.to_csv('test_data_adt_pred.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Estimations vs. Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data to plot estimated and observed values\n",
    "if validation_only:\n",
    "    if trained:\n",
    "        plot_df = pd.read_csv(\"train_data_pred.csv\")\n",
    "    else:\n",
    "        plot_df = train_data_pred\n",
    "else:\n",
    "    if trained:\n",
    "        plot_df = pd.read_csv(\"test_data_pred.csv\")\n",
    "    else:\n",
    "        plot_df = test_data_pred \n",
    "plot_df = plot_df.sort_values(by=['StationId', 'Date', 'Dir', 'Hour'])\n",
    "plot_df = plot_df.set_index(pd.Index(range(plot_df.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to plot estimated and observed values for a day\n",
    "def plot_daily_estimate(frc):\n",
    "    indices = plot_df.index[(plot_df.FRC == frc) & (plot_df.Hour == 0)].tolist()\n",
    "    from_index = np.random.choice(indices, 1)[0]\n",
    "    to_index = from_index + 23\n",
    "    plot_df_sub = plot_df.loc[from_index:to_index, :]\n",
    "    time = pd.date_range(plot_df_sub.Date.iloc[0] + ' 00:00:00', periods=24, freq='H')\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(time, plot_df_sub.PredVolume, 'b-', label='XGBoost', lw=2)\n",
    "    plt.plot(time, plot_df_sub.Volume, 'r--', label='Observed', lw=3)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=24)\n",
    "    plt.ylabel('Volume (vehs/hr)', fontsize=24)\n",
    "    plt.xlabel(\"Time\", fontsize=24)\n",
    "    plt.legend(loc='upper left', shadow=True, fontsize=24)\n",
    "    plt.title('Station ID: {0}, MAE={1}, FRC = {2}'.format(\n",
    "        plot_df_sub.StationId.iloc[0],\n",
    "        round(np.abs(plot_df_sub.PredVolume-plot_df_sub.Volume).mean()),\n",
    "        plot_df_sub.FRC.iloc[0]), fontsize=40)\n",
    "    plt.savefig('frc_{0}.png'.format(frc), dpi = 150)\n",
    "    return(plot_df_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to plot estimated and observed values for a week\n",
    "def plot_weekly_estimate(frc):\n",
    "    indices = plot_df.index[(plot_df.FRC == frc) & (plot_df.Hour == 0) & (plot_df.DayOfWeek == 'Monday')].tolist()\n",
    "    from_index = np.random.choice(indices, 1)[0]\n",
    "    to_index = from_index + 24*7-1\n",
    "    plot_df_sub = plot_df.loc[from_index:to_index, :]\n",
    "    time = pd.date_range(plot_df_sub.Date.iloc[0] + ' 00:00:00', periods=24*7, freq='H')\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(time, plot_df_sub.PredVolume, 'b-', label='XGBoost', lw=2)\n",
    "    plt.plot(time, plot_df_sub.Volume, 'r--', label='Observed', lw=3)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=24)\n",
    "    plt.ylabel('Volume (vehs/hr)', fontsize=24)\n",
    "    plt.xlabel(\"Time\", fontsize=24)\n",
    "    plt.legend(loc='upper left', shadow=True, fontsize=24)\n",
    "    plt.title('Station ID: {0}, MAE={1}, FRC = {2}'.format(\n",
    "        plot_df_sub.StationId.iloc[0],\n",
    "        round(np.abs(plot_df_sub.PredVolume-plot_df_sub.Volume).mean()),\n",
    "        plot_df_sub.FRC.iloc[0]), fontsize=40)\n",
    "    plt.savefig('frc_{0}.png'.format(frc), dpi = 150)\n",
    "    return(plot_df_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot estimated and observed values for a day\n",
    "frc4_daily_plot = plot_daily_estimate(4)\n",
    "save(frc4_daily_plot, 'frc4_daily_plot.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot estimated and observed values for a week\n",
    "frc3_weekly_plot = plot_weekly_estimate(3)\n",
    "save(frc3_weekly_plot, 'frc3_weekly_plot.dat')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
